{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Media Monitoring and Analysis\n",
    "\n",
    "Welcome! This notebook is geared to give you starter examples of how to use ChatGPT for social media monitoring and analysis. Specifically we will look at three use cases:\n",
    "- Sentiment and Emotion Analysis\n",
    "- Topic Extraction\n",
    "- Classification / Categorization\n",
    "\n",
    "For our purposes we will assume we work at Sam's Club (a well-known retail warehouse chain owned by Wal-Mart) and need to look at a series of tweet for our analysis. I'll walk you through all the basic steps needed to do the analysis. \n",
    "\n",
    "NOTE: To make it easier to focus on the process of analysis instead of acquiring the data, I've included a JSON file that has curated output from Twitter (now called, X) in it. If you want to sign up for a developer account so you can get live data, go here: https://developer.twitter.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment and Emotion Analysis\n",
    "\n",
    "The first order of business is to take the data and put it into a format that is easier to analyze. Take a moment to look at the Tweets.json file and see how we get information from Twitter. Notice that the file is a list of dictionaries where each dictionary represents a tweet. We need to manipulate it into something usable. Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our packages \n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# set our key for openai to be used later\n",
    "openai_key = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = openai_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data\n",
    "\n",
    "Now that we have our packages ready to go and our OpenAI API key set we need to read the data info a pandas dataframe to ease our cleaning and analysis efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       created_at                   id               id_str  \\\n",
      "0  Mon May 15 18:21:47 +0000 2023  1658175862045302797  1658175862045302797   \n",
      "1  Mon May 15 17:29:18 +0000 2023  1658162654479888397  1658162654479888397   \n",
      "2  Mon May 15 17:04:13 +0000 2023  1658156342199332864  1658156342199332864   \n",
      "3  Mon May 15 16:54:52 +0000 2023  1658153988703809536  1658153988703809536   \n",
      "4  Mon May 15 16:54:24 +0000 2023  1658153870575521793  1658153870575521793   \n",
      "\n",
      "                                           full_text  truncated  \\\n",
      "0  KitchenAid Mixer Sale on @SamsClub | $90 Off P...      False   \n",
      "1           @KellieShai_ All we need is some milk. üç™      False   \n",
      "2  Happy National Chocolate Chip Day! No denying ...      False   \n",
      "3  This is heartbreaking that less than a year im...      False   \n",
      "4  @VIZIOsupport I bought a vizio tv from @SamsCl...      False   \n",
      "\n",
      "  display_text_range                                             source  \\\n",
      "0           [0, 128]  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
      "1           [13, 40]  <a href=\"https://prod1.sprinklr.com\" rel=\"nofo...   \n",
      "2           [0, 276]  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
      "3           [0, 168]  <a href=\"http://twitter.com/download/android\" ...   \n",
      "4           [0, 279]  <a href=\"http://twitter.com/download/android\" ...   \n",
      "\n",
      "   in_reply_to_status_id in_reply_to_status_id_str  in_reply_to_user_id  ...  \\\n",
      "0                    NaN                      None                  NaN  ...   \n",
      "1           1.658156e+18       1658156342199332864         1.629262e+18  ...   \n",
      "2                    NaN                      None                  NaN  ...   \n",
      "3           1.658154e+18       1658153870575521793         1.620974e+18  ...   \n",
      "4                    NaN                      None         6.915388e+07  ...   \n",
      "\n",
      "  place.contained_within place.bounding_box.type  \\\n",
      "0                    NaN                     NaN   \n",
      "1                    NaN                     NaN   \n",
      "2                    NaN                     NaN   \n",
      "3                    NaN                     NaN   \n",
      "4                    NaN                     NaN   \n",
      "\n",
      "   place.bounding_box.coordinates  geo.type  geo.coordinates coordinates.type  \\\n",
      "0                             NaN       NaN              NaN              NaN   \n",
      "1                             NaN       NaN              NaN              NaN   \n",
      "2                             NaN       NaN              NaN              NaN   \n",
      "3                             NaN       NaN              NaN              NaN   \n",
      "4                             NaN       NaN              NaN              NaN   \n",
      "\n",
      "   coordinates.coordinates  quoted_status.quoted_status_id  \\\n",
      "0                      NaN                             NaN   \n",
      "1                      NaN                             NaN   \n",
      "2                      NaN                             NaN   \n",
      "3                      NaN                             NaN   \n",
      "4                      NaN                             NaN   \n",
      "\n",
      "   quoted_status.quoted_status_id_str  quoted_status.possibly_sensitive  \n",
      "0                                 NaN                               NaN  \n",
      "1                                 NaN                               NaN  \n",
      "2                                 NaN                               NaN  \n",
      "3                                 NaN                               NaN  \n",
      "4                                 NaN                               NaN  \n",
      "\n",
      "[5 rows x 241 columns]\n"
     ]
    }
   ],
   "source": [
    "# Start by inspecting the json file and determining the structure of the data. Remember that the file is a list of dictionaries where each dictionary represents a tweet. \n",
    "# Some are nested dictionaries and some are not. We need to flatten the data so that we can convert it into a DataFrame.\n",
    "# The json_normalize function from pandas is used to convert JSON data into a flat table (DataFrame).\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Open the file named \"Tweets.json\" for reading. The \"with\" statement ensures that the file is properly closed after it is no longer needed.\n",
    "with open(\"Tweets.json\") as file:\n",
    "    # Use the json.load function to load the JSON data from the file into a Python object (usually a list or a dictionary).\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data into a DataFrame. json_normalize flattens the data, meaning it can create a DataFrame from nested JSON data.\n",
    "df = json_normalize(data)\n",
    "\n",
    "# Print the first 5 rows of the DataFrame to see what the data looks like.\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file named \"initaldataframe.csv\" so you can see the progress. The argument index=False means that the DataFrame's index will not be saved in the CSV file.\n",
    "# While this step isn't necessary, it's a good idea to save your work as you go along and to check that the data looks correct.\n",
    "# If you are using VS Code, I highly recommend installing the Excel Viewer extension or Rainbow CSV extension so you can view the CSV file more easily.\n",
    "df.to_csv('initaldataframe.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming Out Unnecessary Columns\n",
    "\n",
    "Now let's take out columns that we obviously won't need for our goals to make the data even more easy to analyze. Take a look at the initaldataframe.csv and determine what columns you think should be kept for our analysis. At this early stage you should keep a column if in doubt. We can always trim it out later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang', 'entities.hashtags', 'entities.symbols', 'entities.user_mentions', 'entities.urls', 'metadata.iso_language_code', 'metadata.result_type', 'user.id', 'user.id_str', 'user.name', 'user.screen_name', 'user.location', 'user.description', 'user.url', 'user.entities.url.urls', 'user.entities.description.urls', 'user.protected', 'user.followers_count', 'user.friends_count', 'user.listed_count', 'user.created_at', 'user.favourites_count', 'user.utc_offset', 'user.time_zone', 'user.geo_enabled', 'user.verified', 'user.statuses_count', 'user.lang', 'user.contributors_enabled', 'user.is_translator', 'user.is_translation_enabled', 'user.profile_background_color', 'user.profile_background_image_url', 'user.profile_background_image_url_https', 'user.profile_background_tile', 'user.profile_image_url', 'user.profile_image_url_https', 'user.profile_banner_url', 'user.profile_link_color', 'user.profile_sidebar_border_color', 'user.profile_sidebar_fill_color', 'user.profile_text_color', 'user.profile_use_background_image', 'user.has_extended_profile', 'user.default_profile', 'user.default_profile_image', 'user.following', 'user.follow_request_sent', 'user.notifications', 'user.translator_type', 'user.withheld_in_countries', 'entities.media', 'extended_entities.media', 'retweeted_status.created_at', 'retweeted_status.id', 'retweeted_status.id_str', 'retweeted_status.full_text', 'retweeted_status.truncated', 'retweeted_status.display_text_range', 'retweeted_status.entities.hashtags', 'retweeted_status.entities.symbols', 'retweeted_status.entities.user_mentions', 'retweeted_status.entities.urls', 'retweeted_status.entities.media', 'retweeted_status.extended_entities.media', 'retweeted_status.metadata.iso_language_code', 'retweeted_status.metadata.result_type', 'retweeted_status.source', 'retweeted_status.in_reply_to_status_id', 'retweeted_status.in_reply_to_status_id_str', 'retweeted_status.in_reply_to_user_id', 'retweeted_status.in_reply_to_user_id_str', 'retweeted_status.in_reply_to_screen_name', 'retweeted_status.user.id', 'retweeted_status.user.id_str', 'retweeted_status.user.name', 'retweeted_status.user.screen_name', 'retweeted_status.user.location', 'retweeted_status.user.description', 'retweeted_status.user.url', 'retweeted_status.user.entities.description.urls', 'retweeted_status.user.protected', 'retweeted_status.user.followers_count', 'retweeted_status.user.friends_count', 'retweeted_status.user.listed_count', 'retweeted_status.user.created_at', 'retweeted_status.user.favourites_count', 'retweeted_status.user.utc_offset', 'retweeted_status.user.time_zone', 'retweeted_status.user.geo_enabled', 'retweeted_status.user.verified', 'retweeted_status.user.statuses_count', 'retweeted_status.user.lang', 'retweeted_status.user.contributors_enabled', 'retweeted_status.user.is_translator', 'retweeted_status.user.is_translation_enabled', 'retweeted_status.user.profile_background_color', 'retweeted_status.user.profile_background_image_url', 'retweeted_status.user.profile_background_image_url_https', 'retweeted_status.user.profile_background_tile', 'retweeted_status.user.profile_image_url', 'retweeted_status.user.profile_image_url_https', 'retweeted_status.user.profile_banner_url', 'retweeted_status.user.profile_link_color', 'retweeted_status.user.profile_sidebar_border_color', 'retweeted_status.user.profile_sidebar_fill_color', 'retweeted_status.user.profile_text_color', 'retweeted_status.user.profile_use_background_image', 'retweeted_status.user.has_extended_profile', 'retweeted_status.user.default_profile', 'retweeted_status.user.default_profile_image', 'retweeted_status.user.following', 'retweeted_status.user.follow_request_sent', 'retweeted_status.user.notifications', 'retweeted_status.user.translator_type', 'retweeted_status.user.withheld_in_countries', 'retweeted_status.geo', 'retweeted_status.coordinates', 'retweeted_status.place', 'retweeted_status.contributors', 'retweeted_status.is_quote_status', 'retweeted_status.retweet_count', 'retweeted_status.favorite_count', 'retweeted_status.favorited', 'retweeted_status.retweeted', 'retweeted_status.possibly_sensitive', 'retweeted_status.lang', 'retweeted_status.user.entities.url.urls', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status.created_at', 'quoted_status.id', 'quoted_status.id_str', 'quoted_status.full_text', 'quoted_status.truncated', 'quoted_status.display_text_range', 'quoted_status.entities.hashtags', 'quoted_status.entities.symbols', 'quoted_status.entities.user_mentions', 'quoted_status.entities.urls', 'quoted_status.metadata.iso_language_code', 'quoted_status.metadata.result_type', 'quoted_status.source', 'quoted_status.in_reply_to_status_id', 'quoted_status.in_reply_to_status_id_str', 'quoted_status.in_reply_to_user_id', 'quoted_status.in_reply_to_user_id_str', 'quoted_status.in_reply_to_screen_name', 'quoted_status.user.id', 'quoted_status.user.id_str', 'quoted_status.user.name', 'quoted_status.user.screen_name', 'quoted_status.user.location', 'quoted_status.user.description', 'quoted_status.user.url', 'quoted_status.user.entities.url.urls', 'quoted_status.user.entities.description.urls', 'quoted_status.user.protected', 'quoted_status.user.followers_count', 'quoted_status.user.friends_count', 'quoted_status.user.listed_count', 'quoted_status.user.created_at', 'quoted_status.user.favourites_count', 'quoted_status.user.utc_offset', 'quoted_status.user.time_zone', 'quoted_status.user.geo_enabled', 'quoted_status.user.verified', 'quoted_status.user.statuses_count', 'quoted_status.user.lang', 'quoted_status.user.contributors_enabled', 'quoted_status.user.is_translator', 'quoted_status.user.is_translation_enabled', 'quoted_status.user.profile_background_color', 'quoted_status.user.profile_background_image_url', 'quoted_status.user.profile_background_image_url_https', 'quoted_status.user.profile_background_tile', 'quoted_status.user.profile_image_url', 'quoted_status.user.profile_image_url_https', 'quoted_status.user.profile_banner_url', 'quoted_status.user.profile_link_color', 'quoted_status.user.profile_sidebar_border_color', 'quoted_status.user.profile_sidebar_fill_color', 'quoted_status.user.profile_text_color', 'quoted_status.user.profile_use_background_image', 'quoted_status.user.has_extended_profile', 'quoted_status.user.default_profile', 'quoted_status.user.default_profile_image', 'quoted_status.user.following', 'quoted_status.user.follow_request_sent', 'quoted_status.user.notifications', 'quoted_status.user.translator_type', 'quoted_status.user.withheld_in_countries', 'quoted_status.geo', 'quoted_status.coordinates', 'quoted_status.place', 'quoted_status.contributors', 'quoted_status.is_quote_status', 'quoted_status.retweet_count', 'quoted_status.favorite_count', 'quoted_status.favorited', 'quoted_status.retweeted', 'quoted_status.lang', 'place.id', 'place.url', 'place.place_type', 'place.name', 'place.full_name', 'place.country_code', 'place.country', 'place.contained_within', 'place.bounding_box.type', 'place.bounding_box.coordinates', 'geo.type', 'geo.coordinates', 'coordinates.type', 'coordinates.coordinates', 'quoted_status.quoted_status_id', 'quoted_status.quoted_status_id_str', 'quoted_status.possibly_sensitive']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all column names\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(all_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base column names you want to keep\n",
    "# copy and paste from the output above to make sure you get the column names correct\n",
    "base_columns_to_keep = ['created_at', 'id', 'full_text', 'in_reply_to_screen_name']\n",
    "\n",
    "# Add the metadata and user columns to the list since those are somewhat interesting to us\n",
    "columns_to_keep = base_columns_to_keep + [col for col in all_columns if col.startswith('metadata.') or col.startswith('user.')]\n",
    "\n",
    "# Keep only the desired columns in the DataFrame\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# print out the results to a csv file to check the results\n",
    "df.to_csv('limitedcolumns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at limitedcolumns.csv, it looks like we can safely remove some columns\n",
    "# Let's remove the columns that have no data in them\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# print out the results to a csv file to check the results\n",
    "df.to_csv('limitedcolumns_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's remove the columns that have the word \"url\" or \"color\" in them since they don't seem to be useful\n",
    "df = df[df.columns.drop(list(df.filter(regex='url|color')))]\n",
    "\n",
    "# print out the results to a csv file to check the results\n",
    "df.to_csv('limitedcolumns_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the withheld_in_countries column because it doesn't have usable values\n",
    "df.drop(columns=['user.withheld_in_countries'], inplace=True)\n",
    "\n",
    "# let's also change all the columns with boolean values to be 1 or 0 instead of True or False\n",
    "# this makes it easier to work with the data later\n",
    "df = df.replace({True: 1, False: 0})\n",
    "\n",
    "# print out the results to a csv file to check the results\n",
    "df.to_csv('limitedcolumns_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have trimmed the data down to 27 columns now and the data looks much more manageable\n",
    "# a couple of more cleanup items and we will be ready to start analyzing the data\n",
    "# let's convert all the column names to lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# finally, let's replace any \".\" in the column names with \"_\" to be consistent\n",
    "df.columns = df.columns.str.replace('.', '_')\n",
    "\n",
    "# print out the results to a csv file to check the results\n",
    "df.to_csv('limitedcolumns_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
